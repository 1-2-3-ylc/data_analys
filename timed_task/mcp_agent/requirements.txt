# 移除 anyio 的固定版本（让 pip 自动选择兼容版本）
# 升级 fastapi 到支持 anyio>=4 的版本（如 0.104.0+）
fastapi>=0.104.0
# 升级 openai 到支持 anyio>=4 的版本（如 1.3.0+）
openai>=1.3.0
# 保留 mcp[cli] 的版本（或指定一个稳定版本）
mcp[cli]==1.18.0
# 其他依赖（根据实际需求保留，如 uvicorn、requests 等）
uvicorn>=0.23.2
requests>=2.31.0
python-multipart>=0.0.6

# MCP项目重构方案

我将帮助您将现有项目重构为真正的MCP(Model Context Protocol)项目。以下是详细的重构计划和实施步骤。

## 重构目标

1. 集成大语言模型(LLM)能力
2. 实现Model Context Protocol标准
3. 构建智能任务决策和工具调用机制
4. 保留原有OCR和数据库功能作为工具插件

## 重构方案

### 1. 新增依赖项

首先更新 [requirements.txt](file://f:\Project_Business\timed_task\mcp_agent\requirements.txt):

```txt
fastapi==0.103.1
uvicorn==0.23.2
requests==2.31.0
python-multipart==0.0.6
anyio==3.7.1
openai>=1.0.0  # OpenAI SDK用于集成大模型
pydantic>=2.0  # 数据模型验证
mcp>=1.0.0     # MCP协议实现库（如果有官方库）
```

### 2. 新增配置文件

在 [config/settings.py](file://f:\Project_Business\timed_task\mcp_agent\config\settings.py) 中新增大模型配置：

```python
# LLM配置
LLM_MODEL = "gpt-4"  # 或其他模型
LLM_API_KEY = "your-api-key-here"
LLM_BASE_URL = "https://api.openai.com/v1"  # 或其他API端点

# MCP配置
MCP_MAX_TOOLS = 10
MCP_CONTEXT_WINDOW = 4096
```

### 3. 新增大模型客户端

创建 [core/llm_client.py](file://f:\Project_Business\timed_task\mcp_agent\core\llm_client.py):

```python
"""
大语言模型客户端，用于与LLM进行交互
"""
from typing import List, Dict, Any, Optional
from openai import OpenAI
from config.settings import LLM_API_KEY, LLM_BASE_URL, LLM_MODEL
import json

class LLMClient:
    def __init__(self):
        self.client = OpenAI(
            api_key=LLM_API_KEY,
            base_url=LLM_BASE_URL
        )
        self.model = LLM_MODEL

    def chat_completion(self, messages: List[Dict[str, str]], tools: Optional[List[Dict]] = None) -> Dict[str, Any]:
        """
        调用LLM进行对话补全
        
        Args:
            messages: 对话历史消息
            tools: 可用工具列表
            
        Returns:
            LLM响应结果
        """
        try:
            kwargs = {
                "model": self.model,
                "messages": messages
            }
            
            if tools:
                kwargs["tools"] = tools
                kwargs["tool_choice"] = "auto"
            
            response = self.client.chat.completions.create(**kwargs)
            return response.choices[0].message.model_dump()
        except Exception as e:
            print(f"LLM调用失败: {str(e)}")
            return {"role": "assistant", "content": f"抱歉，处理请求时出现错误: {str(e)}"}

    def generate_tool_description(self) -> List[Dict]:
        """
        生成工具描述，符合MCP规范
        """
        return [
            {
                "type": "function",
                "function": {
                    "name": "ocr_tool",
                    "description": "光学字符识别工具，用于从图片中提取文字",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "image_path": {
                                "type": "string",
                                "description": "需要识别的图片文件路径"
                            }
                        },
                        "required": ["image_path"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "db_tool",
                    "description": "数据库操作工具，用于存储和查询数据",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "action": {
                                "type": "string",
                                "enum": ["create_table", "insert_data", "query_data"],
                                "description": "数据库操作类型"
                            },
                            "table_name": {
                                "type": "string",
                                "description": "表名"
                            },
                            "data": {
                                "type": "object",
                                "description": "操作数据"
                            }
                        },
                        "required": ["action", "table_name"]
                    }
                }
            }
        ]
```

### 4. 重构Agent核心逻辑

重构 [core/agent.py](file://f:\Project_Business\timed_task\mcp_agent\core\agent.py):

```python
from typing import Dict, Optional, List, Any
from .ocr_client import OCRClient
from .db_client import DBClient
from .llm_client import LLMClient
from utils.text_parser import TextParser
from utils.session_manager import SessionManager
from config.settings import SESSION_EXPIRY_SECONDS
import json

class MCPAgent:
    def __init__(self):
        self.session_manager = SessionManager(SESSION_EXPIRY_SECONDS)
        self.ocr_client = OCRClient()
        self.db_client = DBClient()
        self.llm_client = LLMClient()
        self.parser = TextParser()

    def create_session(self) -> str:
        """创建新会话"""
        return self.session_manager.create_session()

    def process_request(self, session_id: str, user_query: str, image_path: Optional[str] = None) -> Dict:
        """处理用户请求（主入口）"""
        session = self.session_manager.get_session(session_id)
        if not session:
            return {"status": "error", "message": "会话已过期，请重新创建"}

        # 记录用户查询
        self.session_manager.append_session_history(session_id, "user", user_query)

        # 构建对话历史
        messages = self._build_conversation_history(session)
        
        # 添加当前用户消息
        messages.append({"role": "user", "content": user_query})
        
        # 获取工具描述
        tools = self.llm_client.generate_tool_description()
        
        # 调用LLM进行决策
        llm_response = self.llm_client.chat_completion(messages, tools)
        
        # 处理LLM响应
        return self._handle_llm_response(session_id, llm_response, image_path)

    def _build_conversation_history(self, session) -> List[Dict[str, str]]:
        """
        构建对话历史上下文
        """
        history = []
        for item in session.context["history"]:
            history.append({
                "role": item["role"],
                "content": item["content"]
            })
        return history

    def _handle_llm_response(self, session_id: str, llm_response: Dict, image_path: Optional[str]) -> Dict:
        """
        处理LLM响应，包括工具调用
        """
        # 记录助手响应
        self.session_manager.append_session_history(
            session_id, 
            llm_response["role"], 
            llm_response.get("content", "")
        )

        # 检查是否有工具调用
        if llm_response.get("tool_calls"):
            # 处理工具调用
            tool_results = self._execute_tool_calls(session_id, llm_response["tool_calls"], image_path)
            
            # 将工具调用结果添加到对话历史
            messages = self._build_conversation_history(self.session_manager.get_session(session_id))
            messages.extend(tool_results)
            
            # 再次调用LLM获取最终响应
            final_response = self.llm_client.chat_completion(messages)
            
            # 记录最终响应
            self.session_manager.append_session_history(
                session_id, 
                final_response["role"], 
                final_response.get("content", "")
            )
            
            return {
                "status": "success",
                "message": final_response.get("content", ""),
                "tool_calls": llm_response["tool_calls"]
            }
        else:
            # 直接返回LLM响应
            return {
                "status": "success",
                "message": llm_response.get("content", "处理完成")
            }

    def _execute_tool_calls(self, session_id: str, tool_calls: List[Dict], image_path: Optional[str]) -> List[Dict]:
        """
        执行工具调用
        """
        results = []
        
        for tool_call in tool_calls:
            function_name = tool_call["function"]["name"]
            arguments = json.loads(tool_call["function"]["arguments"])
            
            if function_name == "ocr_tool":
                # 调用OCR工具
                ocr_result = self._call_ocr_tool(session_id, image_path or arguments.get("image_path", ""))
                if ocr_result and ocr_result.get("success"):
                    results.append({
                        "tool_call_id": tool_call["id"],
                        "role": "tool",
                        "name": function_name,
                        "content": json.dumps(ocr_result)
                    })
                    
            elif function_name == "db_tool":
                # 调用数据库工具
                action = arguments.get("action")
                table_name = arguments.get("table_name")
                data = arguments.get("data", {})
                
                if action == "create_table":
                    # 创建表逻辑
                    create_sql = data.get("sql", "")
                    db_result = self.db_client.execute_sql(create_sql)
                    results.append({
                        "tool_call_id": tool_call["id"],
                        "role": "tool",
                        "name": function_name,
                        "content": json.dumps(db_result or {"success": False, "error": "未知错误"})
                    })
                elif action == "insert_data":
                    # 插入数据逻辑
                    insert_sql = data.get("sql", "")
                    params = data.get("params", {})
                    db_result = self.db_client.execute_sql(insert_sql, params)
                    results.append({
                        "tool_call_id": tool_call["id"],
                        "role": "tool",
                        "name": function_name,
                        "content": json.dumps(db_result or {"success": False, "error": "未知错误"})
                    })
        
        return results

    def _call_ocr_tool(self, session_id: str, image_path: str) -> Optional[Dict]:
        """调用OCR工具并记录日志"""
        ocr_result = self.ocr_client.call_ocr(image_path)
        if ocr_result:
            self.session_manager.append_session_history(
                session_id, "tool", f"OCR调用成功: {ocr_result['text'][:50]}..."
            )
            self.session_manager.update_session_context(
                session_id, "last_ocr_result", ocr_result
            )
        return ocr_result

    def _call_db_tool(self, session_id: str, create_sql: str, insert_data: Dict) -> Dict:
        """调用数据库工具（创建表+插入数据）并记录日志"""
        # 1. 创建表
        create_result = self.db_client.execute_sql(create_sql)
        if not create_result or not create_result["success"]:
            return {"success": False, "error": "创建表失败"}

        # 2. 插入数据
        insert_sql = f"""
        INSERT INTO {insert_data['table_name']} (raw_text, emails, phones, dates)
        VALUES (%(raw_text)s, %(emails)s, %(phones)s, %(dates)s)
        """
        insert_result = self.db_client.execute_sql(insert_sql, insert_data)
        if insert_result and insert_result["success"]:
            self.session_manager.append_session_history(
                session_id, "tool", f"数据库操作成功: 插入记录ID={insert_result.get('last_insert_id')}"
            )
            return {"success": True, "last_insert_id": insert_result.get("last_insert_id")}
        return {"success": False, "error": "插入数据失败"}
```

### 5. 更新API端点

更新 [api/endpoint.py](file://f:\Project_Business\timed_task\mcp_agent\api\endpoint.py):

```python
from fastapi import APIRouter, Request, HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
import asyncio
from core.agent import MCPAgent
from typing import AsyncGenerator, Dict
import json

router = APIRouter()
agent = MCPAgent()

@router.post("/create-session")
async def create_session() -> Dict[str, str]:
    """创建新会话"""
    session_id = agent.create_session()
    return {"session_id": session_id}

@router.post("/process")
async def process_request(request: Request) -> JSONResponse:
    """处理用户请求（MCP智能响应）"""
    try:
        data = await request.json()
        session_id = data.get("session_id")
        user_query = data.get("query", "")
        image_path = data.get("image_path")

        if not session_id:
            raise HTTPException(status_code=400, detail="缺少session_id")

        # 处理请求
        result = agent.process_request(session_id, user_query, image_path)
        return JSONResponse(content=result)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"处理请求时出错: {str(e)}")
```

### 6. 更新主应用文件

更新 [main.py](file://f:\Project_Business\timed_task\mcp_agent\main.py):

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from api.endpoint import router as api_router
from config.settings import SSE_SERVER_PORT

app = FastAPI(
    title="MCP工具集成智能体",
    description="基于Model Context Protocol的智能体，集成了OCR识别和数据库操作工具",
    version="1.0.0"
)

# 添加CORS中间件
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(api_router, prefix="/api")

# 添加健康检查端点
@app.get("/")
async def root():
    return {
        "message": "MCP工具集成智能体服务正在运行", 
        "version": "1.0.0",
        "docs": "/docs"
    }

# 添加MCP协议相关信息端点
@app.get("/mcp-info")
async def mcp_info():
    return {
        "protocol": "Model Context Protocol",
        "capabilities": [
            "chat_completion",
            "tool_calling",
            "context_management"
        ],
        "supported_tools": [
            "ocr_tool",
            "db_tool"
        ]
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="127.0.0.1", port=SSE_SERVER_PORT, reload=True)
```

### 7. 更新工具描述

更新 [utils/text_parser.py](file://f:\Project_Business\timed_task\mcp_agent\utils\text_parser.py) 以适配MCP:

```python
from typing import Dict, List, Tuple
import re

class TextParser:
    @staticmethod
    def extract_entities(text: str) -> Dict[str, List[str]]:
        """从文本中提取实体（简单示例，可根据实际需求扩展）"""
        # 示例：提取邮箱、电话、日期
        entities = {
            "emails": re.findall(r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b", text),
            "phones": re.findall(r"\b\d{11}\b", text),
            "dates": re.findall(r"\b\d{4}-\d{2}-\d{2}\b", text),
            "raw_text": [text]  # 保留原始文本
        }
        return entities

    @staticmethod
    def generate_table_structure(entities: Dict[str, List[str]], table_name: str) -> Tuple[str, Dict]:
        """根据实体生成表结构SQL和插入数据"""
        # 生成表结构（示例字段，可动态扩展）
        create_sql = f"""
        CREATE TABLE IF NOT EXISTS {table_name} (
            id INT AUTO_INCREMENT PRIMARY KEY,
            raw_text TEXT,
            emails TEXT,
            phones TEXT,
            dates TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        
        # 处理插入数据
        insert_data = {
            "table_name": table_name,
            "raw_text": "\n".join(entities["raw_text"]),
            "emails": ",".join(entities["emails"]),
            "phones": ",".join(entities["phones"]),
            "dates": ",".join(entities["dates"])
        }
        return create_sql.strip(), insert_data

    @staticmethod
    def format_entities_for_llm(entities: Dict[str, List[str]]) -> str:
        """
        格式化实体信息供LLM使用
        """
        formatted = []
        for entity_type, values in entities.items():
            if values:
                formatted.append(f"{entity_type.capitalize()}: {', '.join(values)}")
        return "\n".join(formatted) if formatted else "未检测到特定实体"
```

## 使用示例

重构后的项目可以通过以下方式使用：

### 1. 创建会话
```bash
curl -X POST http://127.0.0.1:8000/api/create-session
```

### 2. 智能处理请求
```bash
curl -X POST http://127.0.0.1:8000/api/process \
  -H "Content-Type: application/json" \
  -d '{
    "session_id": "your_session_id",
    "query": "请识别这张图片中的内容并将重要信息存储到数据库",
    "image_path": "path/to/your/image.jpg"
  }'
```

## 主要改进点

1. **集成大语言模型**：使用OpenAI或其他LLM API进行智能决策
2. **实现MCP协议**：支持工具描述、工具调用等功能
3. **智能任务处理**：基于自然语言理解决定执行哪些工具
4. **上下文管理**：维护对话历史和工具调用记录
5. **标准化API**：提供符合MCP规范的接口

这个重构方案将原有的简单OCR处理系统转变为一个真正的MCP智能体，具备了基于大语言模型的智能决策能力和标准的工具调用机制。